# 5. 가상메모리

논리 주소, 가상 메모리, 페이징 개념을 알아보자

## 물리 주소와 논리 주소

물리 주소

- 실제 데이터가 저장되어있는 메모리의 주소

논리 주소

- 프로세스마다 부여되는 별도의 주소 체계 (0부터 시작한다)

- 즉, 모든 프로세스는 0부터 시작하는 논리 주소를 개별적으로 보유하고 있다

메모리 관리 장치(MMU)

- 논리주소를 물리주소로 변환해주는 하드웨어 장치

- CPU 칩 내부에 있어 접근 속도가 굉장히 빠르다.
- 캐시 효율성, 보안 문제, 단편화 해결을 통한 저장 비용 개선 기능을 가진다.
- TLB가 포함된다. 이외에 다양한 하드웨어가 존재한다.

## 스와핑과 연속 메모리 할당

스와핑

- 오랫동안 사용되지 않은 프로세스를 보조기억장치로 보내고, 당장 필요한 다른 프로세스를 실행하는 메모리 관리 방식

- 보조기억장치로 가는 것을 스왑 아웃, 메모리로 불러오는 것을 스왑 인이라고 한다.

연속 메모리 할당

- 프로세스의 연속적인 메모리 공간 할당 방식을 의미한다.

- 스와핑, 연속 메모리 할당 방식은 외부 단편화 문제를 가진다.

외부 단편화

- 프로세스의 실행과 종료를 반복하며, 실행하는 프로세스보다 작은 메모리 공간만 존재하게 되는 현상이다.

- 이는 메모리 낭비로 이어진다.
- 일정 시점에 프로세스를 묶는 압축을 이용하여 해결할 수 있지만, 이 또한 많은 비용이 발생한다.

내부 단편화

- 특정 프로세스를 일정한 크기로 잘랐을 때, 마지막 대상에 남는 메모리가 발생하는데, 이러한 현상을 의미한다.

## 페이징을 통한 가상 메모리 관리

가상 메모리 (가상 메모리 관리 기법)

- 필요한 데이터만 메모리에 적재하여 실제 메모리보다 더 큰 프로세스를 실행하게 만드는 기법이다.

- RAM 용량보다 큰 프로세스를 실행할 수 있게 해주며, 외부 단편화 문제를 해결해준다.
- 관리 기법으로 페이징, 세그멘테이션이 존재한다.

페이징

- 논리 주소 공간 페이지로, 물리 주소 공간을 프레임으로 나눈 뒤, 페이지를 프레임에 할당하는 가상 메모리 관리 기법

- 페이지는 물리 메모리 내에 불연속적으로 배치될 수 있다.
- 페이징을 이용하면 프로세스를 일정한 크기로 자르며, 물리 메모리에 불연속적으로 배치될 수 있기 떄문에 외부 단편화 문제를 해결할 수 있다. 그러나, 내부 단편화 문제가 발생할 수 있다.
- 페이지 아웃, 페이지 인 개념이 존재한다.

세그멘테이션

- 프로세스를 크기가 아닌 의미 단위(데이터 영역, 코드 영역 등)로 나누어 관리하는 기법이다.(나누어진 대상을 세그먼트라고 한다)

- 세그멘테이션은 사용자에게 직관적이며, 메모리 보호에 유리하다는 장점이 있다. (의미 단위로 나뉘기 때문에, 하나의 세그먼트가 어떤 역할을 하고 있는지 명확하기 때문이다.)
- 세그멘테이션은 외부 단편화에 취약하다. 그러나 내부 단편화에서 자유롭다.

페이지 테이블

- CPU가 메모리에서 데이터를 찾을 수 있도록 (페이지 주소 + 프레임 주소) 형식으로 매핑된 테이블이다.

- 운영체제 커널 안에서 관리하며, 프로세스마다 하나씩 가지고 있다. 또한, 페이지 테이블은 프로세스의 생명주기를 따른다.
- 페이지, 프레임 뿐만 아니라 유효 비트, 보호 비트, 참조 비트, 수정 비트를 필드로 가지고 있다.
    - 유효 비트
        - 페이지 접근 가능 여부를 알려준다.(메모리에 존재하면 1, 보조기억장치에 존재하면 0)

        - 접근 불가능 상태에서 접근할 경우 페이지 폴트 예외가 발생한다.
        - 폴트가 발생할 경우, 기존 작업 내역 백업 → 페이지 폴트 처리 루틴(원하는 페이지를 메모리로 불러옴) → 유효 비트를 1로 변경 방식으로 처리한다.

    - 보호 비트
        - rwx 조합으로 페이지 접근 권한을 제어한다. 000, 111 등으로 구현된다.

    - 참조 비트
        - CPU가 해당 페이지를 이용했으면 1, 이용하지 않았으면 0

        - 페이지 교체 과정에서 최근 사용 여부를 추적하기 위함이다.
    - 수정 비트
        - 더티 비트라고도 부르며, 해당 페이지를 쓴 적이 있으면 1, 없으면 0으로 표기된다.

        - 쓰기가 적용된 페이지를 삭제할 떄, 보조 기억 장치에서도 변경점을 반영해야 하므로, 이 때 사용된다.

페이지 테이블 구조

- 구조는 다음과 같다.

- 페이지 테이블이 (페이지 주소 + 프레임 주소)로 구성되어 있다고 하는데, 페이지 주소가 필요한지 잘 모르겠다. 가상 주소가 항상 0부터 시작해서 그런가? 그러면 시작 주소를 빼기만 하면 될텐데..
- 다른 프로세스는 같은 페이지를 공유하지 않는다.

![image.png](attachment:d1d6d0aa-ae57-4fbe-82ec-781a3c16846f:image.png)

페이지 테이블 베이스 레지스터(PTBR)

- CPU는 페이지 테이블의 위치를 알아야 하며, 해당 주소를 PTBR에 저장한다.

- PTBR은 프로세스 마다 하나씩 보유하고 있으므로 PCB에 기록된다.
- PTBR은 레지스터에 기록되며, 프로세스 간 문맥 교환 발생 시 교체된다.

페이지 테이블 최적화

- TLB(Translation look-aside buffer)
    - 페이지 테이블 형태의 캐시 메모리

    - CPU 칩 안 MMU에 내장된 작은 캐시 메모리에 존재한다.
    - 페이지 번호 + 프레임 번호 + bits 로 구성
    - TLB hit, miss가 존재. miss일 경우 페이지 테이블에서 정보를 가져온다.
    - 기존 페이지 테이블 이용 시, 페이지 테이블 한 번 + 실제 프레임 한번, 총 2번을 메모리에 접근해야 한다. 그러나, TLB hit이 일어날 경우, TLB 한번 + 메모리 한번으로 데이터에 접근할 수 있다.

- 다단계 페이징(계층적 페이징)
    - 페이지 테이블을 계층적으로 구성하는 방식

    - 상위 페이지 테이블이 존재하면, 하위 페이지 테이블은 보조 기억 장치에 보관할 수 있어서 메모리 효율성이 증가한다.
    - 메모리를 N번 건드리기 때문에 속도 문제가 생긴다는 단점이 있을거 같다.
    - → 메모리 효율성 증가 but 접근 속도 하락
        
        ![image.png](attachment:873d9f5b-2d9d-4120-a3dd-3d649b23847f:image.png)
        

페이징 주소 체계

- CPU는 (Page No + offset) 을 제공하며 페이지 테이블은 이를 받아 (Frame No + offset)으로 변환한다. Frame No를 통해 프레임의 시작 주소로 이동한 뒤, offset을 통해 구체적은 데이터로 이동한다.

- offset은 바이트 단위로 작동한다. offset = 2일 경우 frame 시작 주소 + 2 byte값을 반환한다.

페이징 도입 전후 비교

- CPU는 기존 코드 영역에 순차적으로 나열되어 있는 “명령어 + 값 or 주소”를 읽고 해석해 프로세스를 실행했다. 코드 영역을 가리키는 주소는 레지스터에 존재했고 이는 일정한 크기로 증가했다.

- 즉, 페이징 도입 이전에는 `CPU는 레지스터(에 존재하는 물리 주소)를 본다 → 메모리를 본다 → 메모리 값을 가져와 실행한다` 사이클을 거친다.
- 페이징 도입 이후엔 `CPU는 레지스터(에 존재하는 가상 주소)를 본다 → 페이지 테이블에 매핑된 물리 주소를 본다 → 메모리를 본다 → 메모리 값을 가져와 실행한다` 사이클을 거친다.
- 추가적으로, TLB가 도입된 후, `CPU는 레지스터(에 존재하는 가상 주소)를 본다 → TLB에 매핑된 물리 주소를 본다 → 메모리를 본다 → 메모리 값을 가져와 실행한다` 사이클을 거친다.

## 페이지 교체 알고리즘

요구 페이징

- 프로세스를 실행했을 때, 메모리에 필요한 페이지만 적재하는 기법

- 어떠한 페이지 없이 프로세스를 실행하는 것을 순수 요구 페이징이라고 한다.

페이지 교체 알고리즘

- 일정 페이지 개수를 넘어가면 페이지를 교체해줘야 한다.

- 페이지 교체(페이지 폴트)는 성능 저하를 부르기 때문에 최대한 적게 실행되어야 한다. 페이지 교체 알고리즘을 통해 이를 효율적으로 설정할 수 있다.
- 스레싱은 프로세스가 실제로 실행되는 시간보다 페이징에 더 많은 시간을 소요하는 현상을 의미한다.

페이지 교체 알고리즘 종류

- FIFO 페이지 교체 알고리즘

    - 메모리에 가장 먼저 적재된 페이지부터 스왑하는 방식

    - 프로세스 실행 전반에 지속적으로 사용되는 페이지가 자주 교체될 수 있다는 단점이 있다.
    - 6개의 페이지에 1 .. 9 까지의 페이지가 순서대로 사용되는 예시를 생각해보자.
- 최적 페이지 교체 알고리즘
    - 가장 적게 사용될 페이지부터 스왑하는 방식

    - 가장 효율이 좋지만 구현이 어렵기 때문에, best practice로 두고 알고리즘 성능을 비교하기 위해 사용된다.
- LRU 페이지 교체 알고리즘

    - 가장 적게 사용한 페이지부터 스왑하는 방식

페이지 폴트의 종류

- 메이저 페이지 폴트 : 보조기억장치에서 CPU가 원하는 페이지를 읽기 위해 입출력 작업이 필요한 페이지 폴트

- 마이너 페이지 폴트 : 보조기억장치와의 입출력이 필요하지 않는 페이지 폴트

# 6. 파일 시스템

## 파일과 디렉터리

파일 시스템이란

- 보조기억장치의 정보를 파일 및 디렉터리의 형태로 저장하고 관리하는 운영체제 내부 프로그램

- 하나의 OS 내에도 다양한 파일 시스템이 이용되며, 그에 따라 보조기억 장치의 정보를 다루는 방법도 달라지게 된다.

파일

- 파일은 파일 이름 + 파일을 실행하기 위한 정보 + 부가 정보(속성, 메타 데이터로 불리며, 파일 형식, 위치, 크기 등 정보)로 구성되어 있다.

- 파일을 다루는 작업은 모두 운영체제에 의해 이루어진다. → 시스템 콜을 통해 작동한다.
- 프로세스는 파일을 구분하기 위해 “파일 디스크립터”라는 식별값을 이용한다. OS는 프로세스가 파일을 열거나 생성할 때, 해당 파일 디스크립터를 프로세스에 할당한다. (파일에 할당된 임시 번호)
- 파일 디스크립터는 파일 이외에 표준 입출력, 소켓, 파이프 등 다양한 데이터에 할당된다. (따라서, 보통 3부터 할당된다)
- 추가적으로, 파일 디스크립터는 하나의 프로세스 내에서 재사용될 수 있다.(1번 파일이 open, close된 뒤, 2번 파일을 open할 경우, 두 파일은 같은 FD를 할당받을 수 있다)

디렉터리

- 트리 형태의 자료구조로 구성되며, 파일을 관리하는 역할을 한다.(디렉터리 자체를 파일, 디렉터리 정보를 포함한 하나의 파일이라고 간주된다)

- 루트 디렉터리를 중심으로 구성되며, 슬래시를 단위로 구분된다. 이 표현법을 경로라고 한다.
- 디렉터리에 속한 요소 정보는 테이블로 관리되며, 하나의 row를 디렉터리 엔트리라고 한다. 엔트리에는 파일 이름, 저장 위치 정보(아이노드), 생성 및 수정 시간이 저장된다.

파일 할당

- OS는 파일, 디렉터리를 블록 단위(보통 4KB)로 읽고 쓴다. 보통 N개의 블록에 나눠서 저장되며, 보조 기억 장치에 저장된다.

- 하나의 파일, 디렉터리가 저장된 여러 개의 블록을 연결하는 다양한 방식이 존재한다.

    - 연결 할당

        - 연결 리스트와 같이 블록 내에 다음 블록에 대한 주소를 저장하는 방식이다.

        - 엔트리에서 저장 위치 정보에는 첫 번째 블록 주소를 저장한다.
    - 색인 할당
        - 파일 정보가 저장된 모든 블록에 대한 주소를 특정 블록에 저장하는 방식이다.

        - 이를 색인 블록이라고 한다.
        - 작은 파일에 대해 블록 낭비가 발생하는가 ? → 발생한다.
- 어떤 환경에서 어떤 할당 방식을 써야 하는가 ?

## 파일 시스템

파티셔닝

- 보조 기억 장치의 영역을 구분하는 작업이다. 구분된 영역을 파티션이라고 한다.

- 하나의 보조 기억 장치에 다양한 파일 시스템을 사용하기 위해 사용된다.

포매팅

- 파일 시스템을 설정하고, 새로운 데이터를 쓸 준비를 하는 작업

- 파일 시스템 종류, RAID 등을 선택할 수 있다.

아이노드 기반 파일 시스템

- 아이노드 = 파일의 메타 데이터 + 색인 블록 역할을 하는 구조체다. 각 파일, 디렉터리마다 한 개씩 존재한다.

- 하나의 아이노드는 모든 블록의 주소를 보유하고 있다. (아이노드 하나로 연결된 모든 블록을 가져올 수 있음)
- 보조 기억 장치 = 1개의 부트 블록 + N개의 블록 그룹으로 구성된다.
- 아이노드는 블록 그룹에 의해 관리된다. 블록 그룹은 다음과 같이 구성되어 있다.

    - 슈퍼 블록 : 아이노드의 메타 데이터를 저장

    - 그룹 식별자 : 블록 그룹에 대한 메타 데이터를 저장
    - 블록 비트맵 : 현재 블록 그룹 내에서 데이터가 어떻게 할당되었는지를 저장
    - 아이노드 비트맵 : 현재 블록 그룹 내에서 아이노드가 어떻게 할당되었는지를 저장
    - 아이노드 테이블 : 각 파일의 아이노드 정보를 저장
    - 데이터 블록 : 각 파일의 데이터를 저장
- 슈퍼 블록은 전체 블록 그룹의 메타 데이터를 저장하는데, 왜 N개씩 나눠져있지 ? 모든 슈퍼 블록은 같은 값을 가지는건가 ? → 같은 값을 가진다. 손상으로부터 안전해야 하기 때문이다.

- 다음 그림을 확인해보자

![image.png](attachment:b2a9b53c-3b21-4067-ac32-252d9a62b9c9:image.png)

![image.png](attachment:0b8c8201-9daa-4820-8437-2b8eb94eea93:image.png)

파일 디스크립터부터 데이터 블록까지

1. 프로세스가 `open("/home/test.txt")` 호출

2. 커널에서 시스템 콜 호출
3. 내장된 루트 디렉터리의 아이노드를 기준으로, 아이노드 테이블과 데이터 블록을 왕복하며 `/home/test.txt` 의 아이노드를 찾음 (계층 구조로 되어 있기 때문에 효율적으로 찾을 수 있음)
4. 탐색한 아이노드를, 커널의 파일 테이블에 등록 (이 때, 대상 파일명에 대한 아이노드의 포인터를 등록)
5. 프로세스의 FD 테이블에 새로운 엔트리 생성 (해당 파일에 대해 3 값을 가짐)
6. 이후 `read(3)` 호출 → FD 테이블에서 파일 테이블을 찾고 → 아이노드를 찾아서 데이터 블록 접근

![image.png](attachment:6b91adea-42b1-4a0a-bf3e-be0292d0adb9:image.png)

하드 링크와 심볼릭 링크

- 하드 링크

    - 원본 파일과 같은 아이노드를 공유하는 파일

    - 하드 링크 파일을 변경하면 원본 파일에도 영향을 주며, 원본 파일이 삭제돼도 아이노드가 남아 있으면 데이터가 보존된다.
    - 동일한 파일을 여러 이름으로 참조하고 싶을 때 사용된다.
- 심볼릭 링크
    - 원본 파일을 가리키는 파일

    - 원본 파일이 삭제되거나 이동되면 사용이 불가능하다.
    - 파일의 바로가기에서 사용된다.

마운트

- 파일 시스템에서 다른 저장장치의 파일 시스템으로 접근할 수 있도록 파일 시스템을 편입시키는 작업

- 계층 형태를 가지는 파일 구조에서 특정 계층에 새로운 파일 시스템을 연결하는 방식