# 3. 동기화와 교착 상태

<img width="400" height="350" alt="image" src="https://github.com/user-attachments/assets/fc3a0e02-4b50-4087-b47a-16f13e093c58" />

위 그림은 프로세스 A가 공유 메모리 공간에 데이터를 쓰고, 프로세스 B가 해당 메모리 공간을 읽는 상황이다.

이 경우, 두 프로세스는 공유 메모리 공간이라는 자원을 공유하고 있는 셈이다.

<img width="600" height="450" alt="image" src="https://github.com/user-attachments/assets/8654c0cc-e5a2-4817-9855-02c6c6dad31d" />

위 그림은 같은 프로세스의 자원을 공유하는 스레드 간 통신이 이루어지는 상황이다.

멀티 스레드 환경에서는 동일한 프로세스의 스레드 A, B, C가 있고 각각의 프로세스가 할당받은 파일을 수정하는 경우, 스레드들은 파일 자원을 공유하고 있는 셈이다.

<hr>

**공유자원 (shared resource)** : 프로세스 혹은 스레드가 공유하는 자원

**임계 구역 (critical section)** : 공유 자원에 접근하는 코드 중 동시에 실행했을 때 문제가 발생할 수 있는 코드

→ 다수의 프로세스 혹은 스레드가 동시에 공유 자원에 접근할 경우, 실행에 문제가 발생할 수 있다.

→ 동시에 실행되는 프로세스나 스레드가 동시에 임계 구역에 진입하여 실행되면 문제가 발생할 수 있다.

**레이스 컨디션 (Race contion)** : 프로세스 혹은 스레드가 동시에 임계 구역의 코드를 실행하여 문제가 발생하는 상황

레이스 컨디션이 발생하면 자원의 일관성이 손상될 수 있기 때문에 
2개 이상의 프로세스 혹은 스레드가 임계 영역에 진입하고자 한다면, 둘 중 하나는 작업이 끝날 때까지 대기해야 한다.

### 자바로 레이스 컨디션을 구현한 코드

2개의 스레드를 만들어 한 스레드는 0으로 초기화된 공유변수를 10000번동안 1씩 증가시키는 작업을 실행하고,

다른 스레드는 공유 변수를 10000번 동안 1씩 감소시키는 작업을 실행하는 코드이다.

```
public class Race {
  static int sharedData = 0; // 공유 데이터

  public static void main(String[] args) {
    Thread thread1 = new Thread(new Increment());
    Thread thread2 = new Thread(new Increment());

    thread1.start(); // 첫번째 스레드 시작
    thread2.start(); // 두번째 스레드

    try {
      thread1.join(); // 첫번째 스레드 종료 대기
      thread2.join(); // 두번째 스레드 종료 대기
    } catch (InterruptedException e) {
      e.printStackTrace();
    }
    // 최종 공유 데이터 값 출력
    System.out.println("Final value of sharedData : " + sharedData); 
  }

  static class Increment implements Runnable {
    public void run() {
      for (int i = 0; i < 100000; i++) {
        sharedData++; // 공유 데이터 증가
      }
    }
  }

  static class Decrement implements Runnable {
    public void run() {
      for (int i = 0; i < 100000; i++) {
        sharedData--; // 공유 데이터 감소
      }
    }
  }
}
```
<img width="300" height="40" alt="image" src="https://github.com/user-attachments/assets/f674b632-d95b-4b7d-9d2a-fd4d0c92537f" />
<img width="300" height="40" alt="image" src="https://github.com/user-attachments/assets/fde969ca-6ec3-4c3b-90e2-7d07a1469da2" />
<img width="300" height="40" alt="image" src="https://github.com/user-attachments/assets/b1574fd1-cb33-46f7-aee1-ea11c4d5d9bb" />


레이스 컨디션을 구현한 코드를 보면 이론적으로는 0이 출력될 것으로 기대하지만, 

실제로는 레이스 컨디션이 발생해서 매 실행때마다 일정하지 않은 결과가 도출된다.
<hr>

<img width="1612" height="1086" alt="image" src="https://github.com/user-attachments/assets/e4d7e224-3660-4437-9e35-0bf318ccb740" />


## 동기화 기법

레이스 컨디션을 방지하면서 임계 구역을 관리하기 위해서는 프로세스와 스레드가 **동기화(synchronization)** 되어야 한다.

프로세스 혹은 스레드의 **동기화**는 아래 2가지 조건을 준수하며 실행한다.

1. **실행 순서 제어** : 프로세스 및 스레드를 올바른 순서로 실행하기

2. **상호 배제** : 동시에 접근해서는 안되는 자원에 하나의 프로세스 및 스레드만 접근하기
   
실행 순서 제어와 상호 배제를 보장하기 위한 동기화 기법 3가지가 있다.

### 1. 뮤텍스 락 (mutex lock)

동시에 접근해서는 안 되는 자원에 동시 접근이 불가능하도록 상호 백제를 보장하는 동기화 도구 (= 상호 배제를 위한 자물쇠)

**임계 구역에 접근하고자 한다면 반드시 락(lock)을 획득(acquire)해야하고,**

**임계 구역에서의 작업이 끝났다면 락을 해제(release)해야 한다.**

```
lock.acquire(); // 임계구역에 진입하기 위해 프로세스 및 스레드가 공유하는 락을 획득하는 함수
// 임계구역 //
lock.release(); // 임계구역의 작업이 끝나고 락을 해제하는 함수
```

### 레이스 컨디션 문제를 해결하는 코드
```
public class Race {
  static int sharedData = 0;              // 공유 데이터
  static Lock lock = new ReentrantLock(); // ** 락 선언 **

  public static void main(String[] args) {
    Thread thread1 = new Thread(new Increment());
    Thread thread2 = new Thread(new Increment());

    thread1.start(); // 첫번째 스레드 시작
    thread2.start(); // 두번째 스레드

    try {
      thread1.join(); // 첫번째 스레드 종료 대기
      thread2.join(); // 두번째 스레드 종료 대기
    } catch (InterruptedException e) {
      e.printStackTrace();
    }
    // 최종 공유 데이터 값 출력
    System.out.println("Final value of sharedData : " + sharedData); 
  }

  static class Increment implements Runnable {
    public void run() {
      for (int i = 0; i < 100000; i++) {
        lock.lock(); // ** 락 획득 **
        try {
          sharedData++; // 공유 데이터 증가
        } finally {
          lock.unlock(); // ** 락 해제 **
        }
      }
    }
  }

  static class Decrement implements Runnable {
    public void run() {
      for (int i = 0; i < 100000; i++) {
        lock.lock(); // ** 락 획득 **
        try {
          sharedData--; // 공유 데이터 감소
        } finally {
          lock.unlock(); // ** 락 해제**
        }
    }
  }
}
```
** ** 주석 처리한 부분을 삭제하면 레이스 컨디션이 발생한다.

초기 코드랑 다른 점은 임계 구역 진입 전후로 뮤텍스 락을 획득하고 해제한다.

<img width="300" height="40" alt="image" src="https://github.com/user-attachments/assets/3cce41f2-4fd1-411a-8d5d-b3397fd53896" />

뮤텍스 락을 획득하고 해제하여 레이스 컨디션이 발생하지 않아 실제 코드를 실행하면 0이 출력된다.

### 2. 세마포 (Semaphore)

뮤텍스 락은 하나의 공유 자원을 고려하는 동기화 도구이다. 한 번에 하나의 프로세스 및 스레드만 공유 자원을 이용할 수 있는 상황도 있지만,

3개, 4개의 프로세스 및 스레드까지 특정 자원을 이용할 수 있는 상황도 있다. 

이 때 세마포를 이용할 수 있다. 공유 자원이 여러 개 있는 상황에서도 동기화가 가능하다.

- 변수 S : 사용 가능한 공유 자원의 개수(= 임계구역에 진입할 수 있는 프로세스의 개수)를 나타내는 변수
- wait() 함수 : 임계 구역 진입 전 호출하는 함수, wait()를 호출한 프로세스 및 스레드는 임계 구역에 진입한다.
- signal() 함수 : 임계 구역 진입 후 호출하는 함수, 임계 구역에서의 작업이 끝난 프로세스 및 스레드가 호출한다.

```
wait() 
// 임계구역 //
signal()
```

### 레이스 컨디션 문제를 해결하는 코드
```
public class Sema {

    static int sharedData = 0;
    static Semaphore semaphore = new Semaphore(1);

    public static void main(String[] args) {
        Thread thread1 = new Thread(new Race.Increment());
        Thread thread2 = new Thread(new Race.Decrement());

        thread1.start(); // 첫번째 스레드 시작
        thread2.start(); // 두번째 스레드

        try {
            thread1.join(); // 첫번째 스레드 종료 대기
            thread2.join(); // 두번째 스레드 종료 대기
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        // 최종 공유 데이터 값 출력
        System.out.println("Final value of sharedData : " + sharedData);
    }

    static class Increment implements Runnable {
        public void run() {
            for (int i = 0; i < 100000; i++) {
                try {
                    semaphore.acquire(); //세마포 획득
                    sharedData++; // 공유 데이터 증가
                } catch (InterruptedException e) {
                    e.printStackTrace();
                } finally {
                    semaphore.release(); // 세마포 해제
                }
            }
        }
    }

    static class Decrement implements Runnable {
        public void run() {
            for (int i = 0; i < 100000; i++) {
                try {
                    semaphore.acquire(); //세마포 획득
                    sharedData--; // 공유 데이터 감소
                } catch (InterruptedException e) {
                    e.printStackTrace();
                } finally {
                    semaphore.release(); // 세마포 해제
                }
            }
        }
    }
}
```

### 3. 모니터

**조건 변수** : 실행 순서 제어를 위한 동기화 도구, 특정 조건 하에 프로세스를 실행/일시 중단 함으로써 프로세스나 스레드의 실행 순서를 제어할 수 있다.

조건 변수에 대한 wait(), signal() 함수

- wait() : 호출한 프로세스 및 스레드의 상태를 대기 상태로 전환하는 함수

- signal() : wait()로 일시 중지된 프로세스 및 스레드의 실행을 재개하는 함수

→ 아직 특정 프로세스가 실행된 조건이 되지 않았을 때 : wait()를 통해 실행을 중단한다.

→ 특정 프로세스가 실행된 조건이 충족되었을 때 : signal()을 통해 실행을 재개한다.

<hr>

**모니터(monitor)** 

- 공유 자원과 그 공유 자원을 다루는 함수(인터페이스)로 구성된 동기화 도구

- 상호 배제를 위한 동기화뿐만 아니라 실행 순서 제어를 위한 동기화까지 가능

- 작동원리

  <img width="800" height="300" alt="image" src="https://github.com/user-attachments/assets/f2d0c3bf-6e37-4192-869a-fe2d25a2fabd" />


  - 프로세스 및 스레드는 공유 자원에 접근하기 위해 반드시 정해진 공유 자원 연산(인터페이스)을 통해 모니터 내로 진입해야 하고, 모니터 안에 진입하여 실행되는 프로세스 및 스레드는 항상 하나여야 한다.
 
  - 이미 모니터 내로 진입하여 실행 중인 프로세스 및 스레드가 있다면 큐에서 대기해야 한다.  

- 예) 자바의 synchronized 키워드 : synchronized를 사용한 메서드는 하나의 프로세스 및 스레드만 실행한다.
```
public synchronized void example(int value) {
  this.count += value;
}
```

### 스레드 안전 (thread safety)

- 멀티스레드 환경에서 어떤 변수나 함수, 객체에 동시 접근이 이루어져도 실행에 문제가 없는 상태

- 어떤 함수가 스레드 안전하다 = 여러 스레드에 의해 호출되어도 레이스 컨디션이 발생하지 않는다.

- 예) 자바에서 Vector라는 클래스의 add 메서드는 스레드 안전하지만, ArrayList라는 클래스의 add 메서드는 스레드 안전이 보장되지 않는다.

- synchronized 키워드가 없어서 여러 스레드로 동시 실행하면 레이스 컨디션이 발생할 수 있다.

## 교착 상태 (deadlock)

프로세스를 실행하기 위해서는 자원이 필요하다. 

하지만 2개 이상의 프로세스가 각자 가지고 있는 자원을 무작정 기다리면 더 이상 어떤 프로세스도 진행할 수 없는 교착 상태가 발생할 수 있다.

- **교착 상태** : 일어나지 않을 사건을 기다리며 프로세스의 진행이 멈춰버리는 현상
<img width="600" height="200" alt="image" src="https://github.com/user-attachments/assets/0a4aa862-c297-4384-946e-7527e6e4ef26" />

- 게임 프로세스는 자원 A를 점유한 채 웹 브라우저 프로세스가 점유하고 있는 자원 B의 사용을 기다림

- 웹 브라우저 프로세스는 자원 B를 점유한 채 게임 프로세스의 자원 A 사용이 끝나길 기다림

### 교착 상태의 발생 조건

아래 4가지 조건이 모두 만족할 때 교착 상태가 발생할 가능성이 생긴다.

1. 상호 배제

- 한 프로세스가 사용하는 자원을 다른 프로세스가 사용할 수 없는 상호 배제의 상황에서 교착 상태가 발생할 수 있다.

2. 점유와 대기

- 한 프로세스가 어떤 자원을 할당받은 상태(점유)에서 다른 자원 할당 받기를 기다린다면(대기) 교착 상태가 발생할 수 있다.

3. 비선점

- 어떤 프로세스도 다른 프로세스의 자원을 강제로 빼앗지 못하는 경우 교착 상태가 발생할 수 있다.

4. 원형 대기

- 각각의 프로세스가 서로 점유한 자원을 할당받기 위해 원의 형태로 대기할 경우 교착상태가 발생할 수 있다.

### 교착 상태의 해결 방법

자원을 분배하는 방식으로 교착 상태를 **예방**할 수 있고,

조금씩 자원을 할당하다가 교착 상태의 위험이 있을 때 자원을 할당하지 않는 방식으로 교착 상태를 **회피**할 수 있고,

자원을 제약 없이 할당하다가 교착 상태를 **검출한 후 회복**할 수도 있다.

1. 교착 상태 예방 (사전 조치)

- 교착 상태를 발생시키는 4가지 필요 조건 중 하나를 충족하지 못하게 하는 방법

- 한 프로세스에 필요한 자원들을 몰아주고, 그 다음에 다른 프로세스에 필요한 자원을 몰아주면 점유와 대기 조건을 만족 x → 교착 상태 x

- 할당 가능한 모든 자원에 번호를 매기고 오름차순으로 할당하는 경우, 원형 대기 조건을 만족 x → 교착 상태 x

2. 교착 상태 회피 (사전 조치)

- 교착 상태가 발생하지 않을 정도로만 조심하면서 자원을 할당하는 방법
   

3. 교착 상태 검출 후 회복 (사후 조치)

- 교착 상태가 검출되면 프로세스를 **자원 선점을 통해 회복**시키거나, 교착 상테에 놓인 프로세스를 **강제 종료함으로써 회복**시킬 수 있다.

- 자원 선점을 통한 회복 : 교착 상태가 해결될 때까지 다른 프로세스로부터 강제로 자원을 빼앗아 한 프로세스에 몰아서 할당 

# 4. CPU 스케쥴링 

운영체제는 다양한 프로세스와 스레드에 **CPU의 사용을 배분**함으로써 CPU 자원을 관리한다.

- CPU 스케쥴링 : 운영체제가 프로세스에 CPU를 배분하는 방법

- CPU 스케줄링 알고리즘 : CPU 스케쥴링의 절차

- CPU 스케쥴러 : CPU 스케쥴링 알고리즘을 결정하고 수행하는 운영체제의 일부분

- 실행의 문맥이 있다면 모두 스케줄링 대상 (프로세스, 스레드 포함) 

## 우선순위

- CPU의 자원을 공정하게 배분하는 방법은 자원을 할당받을 프로세스의 우선순위가 다르기 때문에 단순히 돌아가면서 할당받는게 아니다.

- 운영체제는 프로세스별 **우선순위(priority)** 를 판단하여 PCB에 명시하고, 우선순위가 높은 프로세스에 CPU의 자원을 더 빨리, 더 많이 할당한다.

- 프로세스는 CPU와 입출력 장치를 오가며 서비스를 실행한다. 해당 장치를 이용하는 작업을 각각 CPU 버스트, 입출력 버스트라고 한다.

- CPU 버스트가 많은 프로세스 = CPU 집중 프로세스

- 입출력 버스트가 많은 프로세스 = 입출력 집중 프로세스

  - CPU 집중 프로세스(CPU bound process)

    → CPU 작업이 많은 프로세스 : 복잡한 수학 연산이나 그래픽 처리 작업을 담당하는 프로세스 등

  - 입출력 집중 프로세스(I/O bound process)

    → 입출력 작업이 많은 프로세스 : 비디오 재생, 디스크 백업 작업을 담당하는 프로세스 등

- 일반적으로 입출력 집중 프로세스는 CPU 집중 프로세스보다 우선순위가 높다. 

  → 이유 : 운영체제가 높은 CPU 활용률(전체 CPU의 가동 시간 중 작업을 처리하는 시간의 비율)을 유지하기 위해

- 두 집중 프로세스가 만약 동시에 CPU의 자원을 요구했다면?

  → 입출력 집중 프로세스를 가능한 빨리 실행시켜 끊임없이 입출력장치를 작동시킨 다음,

  → CPU 집중 프로세스에 집중적으로 CPU를 할하는 것이 더 합리적이다.

## 스케쥴링 큐

운영체제는 프로세스들에게 '자원을 이용하고 싶다면 줄을 서서 기다릴 것'을 요구한다.

→ CPU를 이용하고 싶은 프로세스의 PCB, 메모리로 적재되고 싶은 프로세스의 PCB와 특정 입출력장치를 이용하고 싶은 프로세스의 PCB를 큐에 삽입하여 줄 세우는 것

- 준비 큐 (Ready queue)

  - CPU를 이용하고 싶은 프로세스의 PCB가 서는 줄

  - CPU를 할당받기 위해 대기하는 공간 

- 대기 큐 (Waiting queue)

  - 대기 상태에 접어든 프로세스의 PCB가 서는 줄

  - 입출력 장치 수행 중, 해당 작업이 완료될 때 까지 대기하는 공간
 
  - 같은 입출력 장치를 요구한 프로세스는 같은 대기큐에서 대기한다.
 
  - 대기 큐에서 입출력 장치로부터 인터럽트를 받은 경우, 준비 큐로 이동하게 된다.

 ### 선점형 스케줄링과 비선점형 스케줄링

 스케줄링은 보통 프로세스의 실행이 끝나면 이루어지지만, 프로세스가 종료되지 않았음에도 실행 도중 스케줄링이 수행되는 두 시점이 있다.

 - 실행 도중 스케줄링이 수행되는 시점

  1. 실행상태에서 입출력 작업을 위해 대기 상태로 전환될 때
    
  2. 실행 상태에서 타이머 인터럽트가 발생해 준비 상태로 변경될 때
  
    - 1과 2 모든 상황에서 수행되는 스케줄링 → 선점형 스케줄링

      (뜻 : 운영체제가 프로세스로부터 CPU 자원을 강제로 빼앗아 다른 프로세스에 할당할 수 있는 스케줄링)
    
    - 1 상황에서 수행되는 스케줄링 → 비선점형 스케줄링

- 선점형 스케줄링

  - 프로세스로부터 CPU 자원을 강제로 빼앗다 다른 프로세스에 할당하는 스케줄링

  - 입출력 작업, 타이머 인터럽트에 의해 CPU 자원이 이동한다.

  - CPU 자원을 모든 프로세스에 합리적으로 할당할 수 있지만, 문맥 교환 과정에서 오버헤드가 발생할 수 있다.
 
- 비선점형 스케줄링

  - 프로세스가 종료 혹은 대기 상태가 될 때까지 CPU 자원을 할당하는 스케줄링

  - 입출력 작업을 통해서만 CPU 자원이 이동한다.

  - 문맥 교환이 줄어들어 오버헤드가 적지만, CPU가 급하게 필요한 프로세스에게 CPU 자원을 당장 제공할 수 없다는 단점이 있다. 

## CPU 스케줄링 알고리즘

1. 선입 선처리 스케줄링 (FCFS)

- 준비 큐에 삽입된 순서대로 CPU를 할당하는 방식

- 비선점형 스케줄링

- 먼저 삽입된 프로세스의 오랜 실행 시간으로 인해 나중에 삽입된 프로세스의 실행이 지연되는 문제인 **호위 효과**가 생길 수 있다.

2. 최단 작업 우선 스케줄링 (SJF)

- CPU를 이용하는 시간이 가장 짧은 프로세스로부터 먼저 실행하는 방식

- 비선점형 스케줄링 

- 짧은 프로세스가 지속적으로 입력될 경우, 긴 프로세스에 CPU가 할당받지 못한다는 단점이 있다. 
  이를 기아(아사 : starvation) 문제라고 하며, aging으로 해결할 수 있다.

3. 라운드 로빈 스케줄링 (RR)

- FCFS에 **타임슬라이스**라는 개념이 더해진 방식

- 선점형 스케줄링 

- 타임 슬라이스 (time slice) : 프로세스가 CPU를 사용하도록 정해진 시간 (= 단위 시간)

- 큐에 삽입된 프로세스들이 삽입된 순서대로 CPU를 이용하되, 정해진 단위 시간만큼만 CPU를 이용

- 단위 시간 내에 작업을 완료하지 못하면 문맥 교환이 발생해 다시 큐의 맨 뒤에 삽입된다.

- 단위 시간이 작으면 문맥 교환에 따른 오버헤드가 크게 발생하며, 단위 시간이 크면 선입 선처리 스케줄링과 같은 효과를 가지게 된다 

4. 최소 잔여 시간 우선 스케줄링 (SRT)

- SFJ + RR (최단 작업 우선 스케줄링 + 타임슬라이스 방식)

- 선점형 스케줄링 

- 단위 시간만큼 CPU를 이용하되, 남아있는 작업시간이 가장 적은 프로세스를 다음으로 선택한다. 

5. 우선 순위 스케줄링 (priority)

- 프로세스에 우선순위를 부여하고 가장 높은 우선순위를 가진 프로세스부터 실행하는 스케줄링 방식

- 기아 문제가 발생할 수 있으며, 이를 aging으로 해결할 수 있다.

6. 다단계 큐 스케줄링 (multilevel)

- 우선 순위가 다른 여러 개의 큐를 만든 뒤, 가장 높은 우선순위를 가진 큐에 존재하는 프로세스부터 처리하는 방식

- 프로세스는 큐 간 이동이 불가능하기 때문에, 낮은 우선순위 큐에 존재하는 프로세스가 기아 문제를 겪을 수 있다. → 이를 해결하는게 다단계 피드백 큐 스케줄링

7. 다단계 피드백 큐 스케줄링(multilevel feedback)

- 다단계 큐 스케줄링과 마찬가지로 여러 개의 큐를 대기한다. 해당 큐에서 프로세스가 타임 슬라이스 동안 실행을 완료하지 못한다면, 다음 우선순위 큐에 입력된다. 이를 다시 반복한다.

- 해당 방식은 CPU를 오랫동안 사용해야 하는 ‘CPU 집중 프로세스’의 우선순위는 낮아지고, ‘입출력 집중 프로세스’의 우선순위가 높아지는 특징을 가지고 있다.

- 기아 현상이 발생할 수 있으며, aging을 이용하여 해결할 수 있다.

<hr>

### 정리

<img width="1564" height="806" alt="image" src="https://github.com/user-attachments/assets/cee65838-5e69-4574-abe4-937795478ece" />

<img width="1564" height="768" alt="image" src="https://github.com/user-attachments/assets/d2673460-dfb5-492c-b91d-1ac0ea8d4a3d" />

<img width="1562" height="602" alt="image" src="https://github.com/user-attachments/assets/5796ec2b-a82a-459c-8c83-a0236241a0fb" />



## 리눅스 CPU 스케줄링

- 타임 슬라이스는 프로세스의 가중치에 따라 다르게 할당받을 수 있다.

- 리눅스는 다섯 개의 스케줄링 정책을 이용한다(FIFO, RR, NORMAL, BATCH, IDLE)

- FIFO, RR은 real-time 스케줄러에 의해 이뤼지는 스케줄링이다.

- NORMAL은 CFS라는 스케줄러에 의해 이루어지는데, 완전히 공평한 CPU 시간 배분을 의미한다.

- CFS는 vruntime에 의해 우선 순위가 결정되는데, 작을수록 먼저 스케줄링된다.

- vruntime은 CPU를 할당받아 실행된 시간에 비례하며 프로세스의 가중치(=우선순위)에 반비례한다.

- 따라서, 가중치가 높아질수록 vruntime은 감소하며, 점점 스케줄링 우선권을 가지게 된다.

- CFS의 타임 슬라이스 역시 프로세스의 가중치와 비례하며, 가중치가 높아질수록 높은 타임 슬라이스를 가지게 된다. → CPU를 더 오래 할당받을 수 있다.

- CFS는 RB tree를 통해 vruntime을 관리하며, 최솟값과 최댓값을 효율적으로 찾는다.


## Reference

https://rebugs.tistory.com/325

